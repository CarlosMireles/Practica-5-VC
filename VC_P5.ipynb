{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detección de caras con webcam con detectores de OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m mtcnn_det \u001b[38;5;241m=\u001b[39m MTCNN()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Webcam connection\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m video_capture \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVideoCapture\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Detector index\u001b[39;00m\n\u001b[0;32m     19\u001b[0m det \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "\n",
    "# Models load and setup\n",
    "# VJ\n",
    "haar_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "# DNN\n",
    "dnn_model = \"deploy.prototxt.txt\"\n",
    "dnn_weights = \"res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "net = cv2.dnn.readNetFromCaffe(dnn_model, dnn_weights)\n",
    "# MTCNN\n",
    "mtcnn_det = MTCNN()\n",
    "\n",
    "# Webcam connection\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Detector index\n",
    "det = 1\n",
    "while True:\n",
    "    ret, frame = video_capture.read()    \n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Depending on the active detector\n",
    "    if det == 0:\n",
    "        # VJ\n",
    "        faces = haar_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "        \n",
    "        # Draw bounding boxes\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "    elif det == 1:\n",
    "        # DNN\n",
    "        h, w = frame.shape[:2]\n",
    "        blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300), [104.0, 177.0, 123.0], False, False)\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "\n",
    "        # Draw bounding boxes\n",
    "        for i in range(detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            if confidence > 0.5:\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (x, y, x2, y2) = box.astype(\"int\")\n",
    "                cv2.rectangle(frame, (x, y), (x2, y2), (0, 255, 0), 2)\n",
    "    else: #MTCNN\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = mtcnn_det.detect_faces(rgb_frame)\n",
    "\n",
    "        # Draw bounding boxes\n",
    "        for result in results:\n",
    "            x, y, width, height = result['box']\n",
    "            cv2.rectangle(frame, (x, y), (x + width, y + height), (0, 0, 255), 2)\n",
    "    \n",
    "            # Obtener los puntos clave\n",
    "            keypoints = result['keypoints']\n",
    "            \n",
    "            # Extraer coordenadas de los ojos\n",
    "            left_eye = keypoints['left_eye']\n",
    "            right_eye = keypoints['right_eye']\n",
    "\n",
    "            # Dibujar los ojos (círculos verdes en los ojos)\n",
    "            cv2.circle(frame, left_eye, 5, (0, 255, 0), 2)\n",
    "            cv2.circle(frame, right_eye, 5, (0, 255, 0), 2)\n",
    "\n",
    "            # (Opcional) Dibujar otros puntos clave como nariz y boca\n",
    "            cv2.circle(frame, keypoints['nose'], 5, (255, 0, 0), 2)\n",
    "            cv2.circle(frame, keypoints['mouth_left'], 5, (0, 0, 255), 2)\n",
    "            cv2.circle(frame, keypoints['mouth_right'], 5, (0, 0, 255), 2)\n",
    "    # Shgow results\n",
    "    cv2.imshow('Face Detection', frame)\n",
    "    \n",
    "    # 'd' to change detector, Esc to finish\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('d'):\n",
    "        det += 1\n",
    "        if det > 2:\n",
    "            det = 0\n",
    "    elif key == 27:\n",
    "        break\n",
    "\n",
    "# Close windoews and release camera\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left eye: [np.int64(301), np.int64(276)], Right eye: [np.int64(371), np.int64(283)]\n",
      "Left eye: [np.int64(304), np.int64(275)], Right eye: [np.int64(369), np.int64(281)]\n",
      "Left eye: [np.int64(304), np.int64(276)], Right eye: [np.int64(370), np.int64(284)]\n",
      "Left eye: [np.int64(306), np.int64(276)], Right eye: [np.int64(372), np.int64(285)]\n",
      "Left eye: [np.int64(305), np.int64(276)], Right eye: [np.int64(375), np.int64(280)]\n",
      "Left eye: [np.int64(229), np.int64(231)], Right eye: [np.int64(236), np.int64(232)]\n",
      "Left eye: [np.int64(305), np.int64(276)], Right eye: [np.int64(371), np.int64(283)]\n",
      "Left eye: [np.int64(305), np.int64(273)], Right eye: [np.int64(371), np.int64(278)]\n",
      "Left eye: [np.int64(307), np.int64(269)], Right eye: [np.int64(372), np.int64(272)]\n",
      "Left eye: [np.int64(307), np.int64(266)], Right eye: [np.int64(371), np.int64(270)]\n",
      "Left eye: [np.int64(307), np.int64(266)], Right eye: [np.int64(369), np.int64(269)]\n",
      "Left eye: [np.int64(306), np.int64(263)], Right eye: [np.int64(370), np.int64(267)]\n",
      "Left eye: [np.int64(305), np.int64(264)], Right eye: [np.int64(368), np.int64(269)]\n",
      "Left eye: [np.int64(303), np.int64(261)], Right eye: [np.int64(367), np.int64(264)]\n",
      "Left eye: [np.int64(300), np.int64(256)], Right eye: [np.int64(365), np.int64(261)]\n",
      "Left eye: [np.int64(294), np.int64(258)], Right eye: [np.int64(359), np.int64(265)]\n",
      "Left eye: [np.int64(288), np.int64(260)], Right eye: [np.int64(349), np.int64(263)]\n",
      "Left eye: [np.int64(289), np.int64(258)], Right eye: [np.int64(351), np.int64(260)]\n",
      "Left eye: [np.int64(294), np.int64(257)], Right eye: [np.int64(355), np.int64(261)]\n",
      "Left eye: [np.int64(296), np.int64(256)], Right eye: [np.int64(356), np.int64(260)]\n",
      "Left eye: [np.int64(296), np.int64(255)], Right eye: [np.int64(356), np.int64(260)]\n",
      "Left eye: [np.int64(295), np.int64(254)], Right eye: [np.int64(355), np.int64(257)]\n",
      "Left eye: [np.int64(295), np.int64(253)], Right eye: [np.int64(355), np.int64(256)]\n",
      "Left eye: [np.int64(295), np.int64(253)], Right eye: [np.int64(356), np.int64(256)]\n",
      "Left eye: [np.int64(294), np.int64(251)], Right eye: [np.int64(356), np.int64(254)]\n",
      "Left eye: [np.int64(294), np.int64(254)], Right eye: [np.int64(356), np.int64(258)]\n",
      "Left eye: [np.int64(294), np.int64(253)], Right eye: [np.int64(357), np.int64(257)]\n",
      "Left eye: [np.int64(295), np.int64(254)], Right eye: [np.int64(357), np.int64(256)]\n",
      "Left eye: [np.int64(298), np.int64(254)], Right eye: [np.int64(357), np.int64(256)]\n",
      "Left eye: [np.int64(403), np.int64(193)], Right eye: [np.int64(407), np.int64(192)]\n",
      "Left eye: [np.int64(300), np.int64(252)], Right eye: [np.int64(359), np.int64(254)]\n",
      "Left eye: [np.int64(300), np.int64(250)], Right eye: [np.int64(361), np.int64(252)]\n",
      "Left eye: [np.int64(300), np.int64(250)], Right eye: [np.int64(362), np.int64(253)]\n",
      "Left eye: [np.int64(299), np.int64(253)], Right eye: [np.int64(361), np.int64(253)]\n",
      "Left eye: [np.int64(298), np.int64(251)], Right eye: [np.int64(360), np.int64(255)]\n",
      "Left eye: [np.int64(298), np.int64(253)], Right eye: [np.int64(360), np.int64(256)]\n",
      "Left eye: [np.int64(297), np.int64(253)], Right eye: [np.int64(358), np.int64(255)]\n",
      "Left eye: [np.int64(294), np.int64(253)], Right eye: [np.int64(357), np.int64(255)]\n",
      "Left eye: [np.int64(292), np.int64(254)], Right eye: [np.int64(357), np.int64(256)]\n",
      "Left eye: [np.int64(290), np.int64(255)], Right eye: [np.int64(356), np.int64(257)]\n",
      "Left eye: [np.int64(290), np.int64(257)], Right eye: [np.int64(353), np.int64(258)]\n",
      "Left eye: [np.int64(290), np.int64(257)], Right eye: [np.int64(355), np.int64(261)]\n",
      "Left eye: [np.int64(291), np.int64(259)], Right eye: [np.int64(355), np.int64(263)]\n",
      "Left eye: [np.int64(288), np.int64(261)], Right eye: [np.int64(354), np.int64(263)]\n",
      "Left eye: [np.int64(283), np.int64(262)], Right eye: [np.int64(352), np.int64(265)]\n",
      "Left eye: [np.int64(282), np.int64(265)], Right eye: [np.int64(352), np.int64(268)]\n",
      "Left eye: [np.int64(283), np.int64(268)], Right eye: [np.int64(353), np.int64(272)]\n",
      "Left eye: [np.int64(282), np.int64(270)], Right eye: [np.int64(354), np.int64(275)]\n",
      "Left eye: [np.int64(287), np.int64(270)], Right eye: [np.int64(356), np.int64(276)]\n",
      "Left eye: [np.int64(293), np.int64(268)], Right eye: [np.int64(363), np.int64(273)]\n",
      "Left eye: [np.int64(295), np.int64(268)], Right eye: [np.int64(364), np.int64(274)]\n",
      "Left eye: [np.int64(292), np.int64(269)], Right eye: [np.int64(361), np.int64(273)]\n",
      "Left eye: [np.int64(289), np.int64(268)], Right eye: [np.int64(358), np.int64(271)]\n",
      "Left eye: [np.int64(287), np.int64(268)], Right eye: [np.int64(355), np.int64(272)]\n",
      "Left eye: [np.int64(285), np.int64(268)], Right eye: [np.int64(352), np.int64(270)]\n",
      "Left eye: [np.int64(286), np.int64(268)], Right eye: [np.int64(354), np.int64(271)]\n",
      "Left eye: [np.int64(115), np.int64(385)], Right eye: [np.int64(133), np.int64(385)]\n",
      "Left eye: [np.int64(286), np.int64(268)], Right eye: [np.int64(354), np.int64(272)]\n",
      "Left eye: [np.int64(287), np.int64(268)], Right eye: [np.int64(355), np.int64(272)]\n",
      "Left eye: [np.int64(288), np.int64(269)], Right eye: [np.int64(356), np.int64(273)]\n",
      "Left eye: [np.int64(288), np.int64(269)], Right eye: [np.int64(356), np.int64(273)]\n",
      "Left eye: [np.int64(288), np.int64(269)], Right eye: [np.int64(356), np.int64(273)]\n",
      "Left eye: [np.int64(288), np.int64(269)], Right eye: [np.int64(356), np.int64(273)]\n",
      "Left eye: [np.int64(285), np.int64(271)], Right eye: [np.int64(351), np.int64(274)]\n",
      "Left eye: [np.int64(272), np.int64(270)], Right eye: [np.int64(340), np.int64(274)]\n",
      "Left eye: [np.int64(270), np.int64(269)], Right eye: [np.int64(339), np.int64(274)]\n",
      "Left eye: [np.int64(271), np.int64(271)], Right eye: [np.int64(340), np.int64(275)]\n",
      "Left eye: [np.int64(279), np.int64(270)], Right eye: [np.int64(348), np.int64(275)]\n",
      "Left eye: [np.int64(298), np.int64(269)], Right eye: [np.int64(367), np.int64(271)]\n",
      "Left eye: [np.int64(321), np.int64(268)], Right eye: [np.int64(385), np.int64(271)]\n",
      "Left eye: [np.int64(324), np.int64(267)], Right eye: [np.int64(387), np.int64(270)]\n",
      "Left eye: [np.int64(321), np.int64(267)], Right eye: [np.int64(386), np.int64(270)]\n",
      "Left eye: [np.int64(312), np.int64(268)], Right eye: [np.int64(376), np.int64(267)]\n",
      "Left eye: [np.int64(300), np.int64(267)], Right eye: [np.int64(368), np.int64(267)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from mtcnn import MTCNN\n",
    "\n",
    "# Inicializar el detector MTCNN\n",
    "mtcnn_det = MTCNN()\n",
    "\n",
    "# Capturar video desde la cámara\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convertir el frame a RGB (MTCNN espera imágenes en RGB)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Detectar caras y puntos clave\n",
    "    results = mtcnn_det.detect_faces(rgb_frame)\n",
    "\n",
    "    # Verificar si hay resultados\n",
    "    if results:\n",
    "        # Dibujar recuadros y puntos clave (ojos, nariz, boca)\n",
    "        for result in results:\n",
    "            # Dibujar la caja delimitadora de la cara\n",
    "            x, y, width, height = result['box']\n",
    "            cv2.rectangle(frame, (x, y), (x + width, y + height), (0, 0, 255), 2)\n",
    "\n",
    "            # Obtener los puntos clave\n",
    "            keypoints = result.get('keypoints', {})\n",
    "            \n",
    "            # Verificar si hay puntos clave (ojos, nariz, boca)\n",
    "            if keypoints:\n",
    "                left_eye = keypoints.get('left_eye')\n",
    "                right_eye = keypoints.get('right_eye')\n",
    "                nose = keypoints.get('nose')\n",
    "                mouth_left = keypoints.get('mouth_left')\n",
    "                mouth_right = keypoints.get('mouth_right')\n",
    "\n",
    "                # Comprobar si los ojos fueron detectados\n",
    "                if left_eye and right_eye:\n",
    "                    # Dibujar los ojos (círculos verdes en los ojos)\n",
    "                    cv2.circle(frame, left_eye, 5, (0, 255, 0), 2)\n",
    "                    cv2.circle(frame, right_eye, 5, (0, 255, 0), 2)\n",
    "\n",
    "                # Dibujar otros puntos clave si están disponibles\n",
    "                if nose:\n",
    "                    cv2.circle(frame, nose, 5, (255, 0, 0), 2)\n",
    "                if mouth_left:\n",
    "                    cv2.circle(frame, mouth_left, 5, (0, 0, 255), 2)\n",
    "                if mouth_right:\n",
    "                    cv2.circle(frame, mouth_right, 5, (0, 0, 255), 2)\n",
    "\n",
    "    else:\n",
    "        print(\"No se detectaron caras.\")\n",
    "\n",
    "    # Mostrar el frame con los recuadros y puntos clave\n",
    "    cv2.imshow(\"Detección de Rostros\", frame)\n",
    "\n",
    "    # Salir si se presiona 'Esc'\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# Liberar la cámara y cerrar las ventanas\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from mtcnn import MTCNN\n",
    "import numpy as np\n",
    "\n",
    "# Inicializar el detector MTCNN\n",
    "mtcnn_det = MTCNN()\n",
    "\n",
    "\n",
    "# Cargar las imágenes de las marcas de colores\n",
    "marca_azul = cv2.imread('azul.png', cv2.IMREAD_UNCHANGED)\n",
    "marca_amarilla = cv2.imread('amarillo.png', cv2.IMREAD_UNCHANGED)\n",
    "escudo = cv2.imread('escudo.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# Función para superponer una imagen con transparencia\n",
    "def superponer_imagen(bg, fg, x, y, w, h):\n",
    "    # Redimensionar la imagen de la marca al ancho y alto deseado\n",
    "    fg = cv2.resize(fg, (w, h))\n",
    "\n",
    "    # Obtener los canales de la imagen (RGBA)\n",
    "    for i in range(3):  # Solo combinar los canales RGB\n",
    "        bg[y:y+h, x:x+w, i] = fg[:, :, i] * (fg[:, :, 3] / 255.0) + bg[y:y+h, x:x+w, i] * (1 - fg[:, :, 3] / 255.0)\n",
    "\n",
    "# Capturar video desde la cámara\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convertir el frame a RGB (MTCNN espera imágenes en RGB)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Detectar caras y puntos clave\n",
    "    results = mtcnn_det.detect_faces(rgb_frame)\n",
    "\n",
    "    # Verificar si hay resultados\n",
    "    if results:\n",
    "        for result in results:\n",
    "            # Dibujar la caja delimitadora de la cara\n",
    "            x, y, width, height = result['box']\n",
    "            cv2.rectangle(frame, (x, y), (x + width, y + height), (0, 0, 255), 2)\n",
    "\n",
    "            # Obtener los puntos clave (ojos)\n",
    "            keypoints = result.get('keypoints', {})\n",
    "            if keypoints:\n",
    "                left_eye = keypoints.get('left_eye')\n",
    "                right_eye = keypoints.get('right_eye')\n",
    "                nose = keypoints.get('nose')\n",
    "                mouth_left = keypoints.get('mouth_left')\n",
    "                mouth_right = keypoints.get('mouth_right')\n",
    "\n",
    "                if left_eye and right_eye:\n",
    "\n",
    "                    # Calcular las posiciones para las marcas de colores debajo de los ojos\n",
    "                    marca_amarilla_x = left_eye[0] - 20  # Ajustar horizontalmente\n",
    "                    marca_amarilla_y = left_eye[1] + 10  # Colocar debajo del ojo izquierdo\n",
    "\n",
    "                    marca_azul_x = right_eye[0] - 20  # Ajustar horizontalmente\n",
    "                    marca_azul_y = right_eye[1] + 10  # Colocar debajo del ojo derecho\n",
    "\n",
    "                    # Superponer las marcas debajo de los ojos\n",
    "                    superponer_imagen(frame, marca_amarilla, marca_amarilla_x, marca_amarilla_y, 45, 25)\n",
    "                    superponer_imagen(frame, marca_azul, marca_azul_x, marca_azul_y, 45, 25)\n",
    "\n",
    "                if mouth_left and mouth_right:\n",
    "                    # Calcular la distancia entre mouth_left y mouth_right\n",
    "                    mouth_width = np.linalg.norm(np.array(mouth_left) - np.array(mouth_right))\n",
    "\n",
    "                    # Estimar la posición de la parte superior e inferior de la boca\n",
    "                    mouth_center_x = ((mouth_left[0] + mouth_right[0]) // 2) - 20\n",
    "                    mouth_center_y = ((mouth_left[1] + mouth_right[1]) // 2) - 10\n",
    "\n",
    "                    # Estimación de la altura de la boca\n",
    "                    mouth_height = abs(mouth_left[1] - nose[1])  # Usar la nariz como referencia para la boca superior\n",
    "\n",
    "                    # Umbral para determinar si la boca está abierta o cerrada\n",
    "                    if mouth_height > mouth_width * 0.75:\n",
    "                        cv2.putText(frame, \"Boca abierta\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                        superponer_imagen(frame, escudo, mouth_center_x, left_eye[1] - 120, 100, 65)\n",
    "                    else:\n",
    "                        cv2.putText(frame, \"Boca cerrada\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "    # Mostrar el frame con los recuadros, gafas de sol y marcas de colores\n",
    "    cv2.imshow(\"Detección de Rostros con Gafas y Marcas\", frame)\n",
    "\n",
    "    # Salir si se presiona 'Esc'\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# Liberar la cámara y cerrar las ventanas\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
